{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ZLln9uQPYpIC"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# importing utilities\n",
        "import os\n",
        "import sys\n",
        "from datetime import datetime\n",
        "\n",
        "# importing data science libraries\n",
        "import pandas as pd\n",
        "import random as rd\n",
        "import numpy as np\n",
        "\n",
        "# importing pytorch libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import autograd\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# import visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import seaborn as sns\n",
        "from IPython.display import Image, display\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "# ignore potential warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%matplotlib inline\n",
        "USE_CUDA = True\n",
        "# init deterministic seed\n",
        "seed_value = 1234 #4444 #3333 #2222 #1111 #1234\n",
        "rd.seed(seed_value) # set random seed\n",
        "np.random.seed(seed_value) # set numpy seed\n",
        "torch.manual_seed(seed_value) # set pytorch seed CPU\n",
        "if (torch.backends.cudnn.version() != None and USE_CUDA == True):\n",
        "    torch.cuda.manual_seed(seed_value) # set pytorch seed GPU\n",
        "\n",
        "# load the dataset into the notebook kernel\n",
        "ori_dataset = pd.read_csv('/content/fraud_dataset_v2.csv')\n",
        "\n",
        "# select categorical attributes to be \"one-hot\" encoded\n",
        "categorical_attr_names = ['KTOSL', 'PRCTR', 'BSCHL', 'HKONT']\n",
        "\n",
        "# encode categorical attributes into a binary one-hot encoded representation\n",
        "ori_dataset_categ_transformed = pd.get_dummies(ori_dataset[categorical_attr_names])\n",
        "\n",
        "\n",
        "# select categorical attributes to be \"one-hot\" encoded\n",
        "categorical_attr_names = ['KTOSL', 'PRCTR', 'BSCHL', 'HKONT']\n",
        "\n",
        "# encode categorical attributes into a binary one-hot encoded representation\n",
        "ori_dataset_categ_transformed = pd.get_dummies(ori_dataset[categorical_attr_names])\n",
        "\n",
        "# select \"DMBTR\" vs. \"WRBTR\" attribute\n",
        "numeric_attr_names = ['DMBTR', 'WRBTR']\n",
        "\n",
        "# add a small epsilon to eliminate zero values from data for log scaling\n",
        "numeric_attr = ori_dataset[numeric_attr_names] + 1e-7\n",
        "numeric_attr = numeric_attr.apply(np.log)\n",
        "\n",
        "# normalize all numeric attributes to the range [0,1]\n",
        "ori_dataset_numeric_attr = (numeric_attr - numeric_attr.min()) / (numeric_attr.max() - numeric_attr.min())\n",
        "\n",
        "# merge categorical and numeric subsets\n",
        "ori_subset_transformed = pd.concat([ori_dataset_categ_transformed, ori_dataset_numeric_attr], axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # implementation of the encoder network\n",
        "# class encoder(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "\n",
        "#         super(encoder, self).__init__()\n",
        "\n",
        "#         # specify layer 1 - in 618, out 512\n",
        "#         self.encoder_L1 = nn.Linear(in_features=ori_subset_transformed.shape[1], out_features=512, bias=True) # add linearity\n",
        "#         nn.init.xavier_uniform_(self.encoder_L1.weight) # init weights according to [9]\n",
        "#         self.encoder_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True) # add non-linearity according to [10]\n",
        "\n",
        "#         # specify layer 2 - in 512, out 256\n",
        "#         self.encoder_L2 = nn.Linear(512, 256, bias=True)\n",
        "#         nn.init.xavier_uniform_(self.encoder_L2.weight)\n",
        "#         self.encoder_R2 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
        "\n",
        "#         # specify layer 3 - in 256, out 128\n",
        "#         self.encoder_L3 = nn.Linear(256, 128, bias=True)\n",
        "#         nn.init.xavier_uniform_(self.encoder_L3.weight)\n",
        "#         self.encoder_R3 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
        "\n",
        "#         # specify layer 4 - in 128, out 64\n",
        "#         self.encoder_L4 = nn.Linear(128, 64, bias=True)\n",
        "#         nn.init.xavier_uniform_(self.encoder_L4.weight)\n",
        "#         self.encoder_R4 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
        "\n",
        "#         # specify layer 5 - in 64, out 32\n",
        "#         self.encoder_L5 = nn.Linear(64, 32, bias=True)\n",
        "#         nn.init.xavier_uniform_(self.encoder_L5.weight)\n",
        "#         self.encoder_R5 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
        "\n",
        "#         # specify layer 6 - in 32, out 16\n",
        "#         self.encoder_L6 = nn.Linear(32, 16, bias=True)\n",
        "#         nn.init.xavier_uniform_(self.encoder_L6.weight)\n",
        "#         self.encoder_R6 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
        "\n",
        "#         # specify layer 7 - in 16, out 8\n",
        "#         self.encoder_L7 = nn.Linear(16, 8, bias=True)\n",
        "#         nn.init.xavier_uniform_(self.encoder_L7.weight)\n",
        "#         self.encoder_R7 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
        "\n",
        "#         # specify layer 8 - in 8, out 4\n",
        "#         self.encoder_L8 = nn.Linear(8, 4, bias=True)\n",
        "#         nn.init.xavier_uniform_(self.encoder_L8.weight)\n",
        "#         self.encoder_R8 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
        "\n",
        "#         # specify layer 9 - in 4, out 3\n",
        "#         self.encoder_L9 = nn.Linear(4, 3, bias=True)\n",
        "#         nn.init.xavier_uniform_(self.encoder_L9.weight)\n",
        "#         self.encoder_R9 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
        "\n",
        "#         # init dropout layer with probability p\n",
        "#         self.dropout = nn.Dropout(p=0.0, inplace=True)\n",
        "\n",
        "#     def forward(self, x):\n",
        "\n",
        "#         # define forward pass through the network\n",
        "#         x = self.encoder_R1(self.dropout(self.encoder_L1(x)))\n",
        "#         x = self.encoder_R2(self.dropout(self.encoder_L2(x)))\n",
        "#         x = self.encoder_R3(self.dropout(self.encoder_L3(x)))\n",
        "#         x = self.encoder_R4(self.dropout(self.encoder_L4(x)))\n",
        "#         x = self.encoder_R5(self.dropout(self.encoder_L5(x)))\n",
        "#         x = self.encoder_R6(self.dropout(self.encoder_L6(x)))\n",
        "#         x = self.encoder_R7(self.dropout(self.encoder_L7(x)))\n",
        "#         x = self.encoder_R8(self.dropout(self.encoder_L8(x)))\n",
        "#         x = self.encoder_R9(self.encoder_L9(x)) # don't apply dropout to the AE bottleneck\n",
        "\n",
        "#         return x\n",
        "\n",
        "# # # init training network classes / architectures\n",
        "# # encoder_train = encoder()\n",
        "\n",
        "# # # push to cuda if cudnn is available\n",
        "# # if (torch.backends.cudnn.version() != None and USE_CUDA == True):\n",
        "# #     encoder_train = encoder().cuda()\n"
      ],
      "metadata": {
        "id": "qJj0SBUpZNEe"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implementation of the shallow encoder network\n",
        "# containing only a single layer\n",
        "class shallow_encoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(shallow_encoder, self).__init__()\n",
        "\n",
        "        # specify layer 1 - in 618, out 3\n",
        "        self.encoder_L1 = nn.Linear(in_features=ori_subset_transformed.shape[1], out_features=3, bias=True) # add linearity\n",
        "        nn.init.xavier_uniform_(self.encoder_L1.weight) # init weights according to [9]\n",
        "        self.encoder_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True) # add non-linearity according to [10]\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # define forward pass through the network\n",
        "        x = self.encoder_R1(self.encoder_L1(x)) # don't apply dropout to the AE bottleneck\n",
        "\n",
        "        return x\n",
        "\n",
        "# init training network classes / architectures\n",
        "encoder_train = shallow_encoder()\n",
        "\n",
        "# push to cuda if cudnn is available\n",
        "if (torch.backends.cudnn.version() != None and USE_CUDA == True):\n",
        "    encoder_train = shallow_encoder().cuda()\n",
        "\n"
      ],
      "metadata": {
        "id": "E0iht4p4lO7h"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # implementation of the decoder network\n",
        "# class decoder(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "\n",
        "#         super(decoder, self).__init__()\n",
        "\n",
        "#         # specify layer 1 - in 3, out 4\n",
        "#         self.decoder_L1 = nn.Linear(in_features=3, out_features=4, bias=True) # add linearity\n",
        "#         nn.init.xavier_uniform_(self.decoder_L1.weight)  # init weights according to [9]\n",
        "#         self.decoder_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True) # add non-linearity according to [10]\n",
        "\n",
        "#         # specify layer 2 - in 4, out 8\n",
        "#         self.decoder_L2 = nn.Linear(4, 8, bias=True)\n",
        "#         nn.init.xavier_uniform_(self.decoder_L2.weight)\n",
        "#         self.decoder_R2 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
        "\n",
        "#         # specify layer 3 - in 8, out 16\n",
        "#         self.decoder_L3 = nn.Linear(8, 16, bias=True)\n",
        "#         nn.init.xavier_uniform_(self.decoder_L3.weight)\n",
        "#         self.decoder_R3 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
        "\n",
        "#         # specify layer 4 - in 16, out 32\n",
        "#         self.decoder_L4 = nn.Linear(16, 32, bias=True)\n",
        "#         nn.init.xavier_uniform_(self.decoder_L4.weight)\n",
        "#         self.decoder_R4 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
        "\n",
        "#         # specify layer 5 - in 32, out 64\n",
        "#         self.decoder_L5 = nn.Linear(32, 64, bias=True)\n",
        "#         nn.init.xavier_uniform_(self.decoder_L5.weight)\n",
        "#         self.decoder_R5 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
        "\n",
        "#         # specify layer 6 - in 64, out 128\n",
        "#         self.decoder_L6 = nn.Linear(64, 128, bias=True)\n",
        "#         nn.init.xavier_uniform_(self.decoder_L6.weight)\n",
        "#         self.decoder_R6 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
        "\n",
        "#         # specify layer 7 - in 128, out 256\n",
        "#         self.decoder_L7 = nn.Linear(128, 256, bias=True)\n",
        "#         nn.init.xavier_uniform_(self.decoder_L7.weight)\n",
        "#         self.decoder_R7 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
        "\n",
        "#         # specify layer 8 - in 256, out 512\n",
        "#         self.decoder_L8 = nn.Linear(256, 512, bias=True)\n",
        "#         nn.init.xavier_uniform_(self.decoder_L8.weight)\n",
        "#         self.decoder_R8 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
        "\n",
        "#         # specify layer 9 - in 512, out 618\n",
        "#         self.decoder_L9 = nn.Linear(in_features=512, out_features=ori_subset_transformed.shape[1], bias=True)\n",
        "#         nn.init.xavier_uniform_(self.decoder_L9.weight)\n",
        "#         self.decoder_R9 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
        "\n",
        "#         # init dropout layer with probability p\n",
        "#         self.dropout = nn.Dropout(p=0.0, inplace=True)\n",
        "\n",
        "#     def forward(self, x):\n",
        "\n",
        "#         # define forward pass through the network\n",
        "#         x = self.decoder_R1(self.dropout(self.decoder_L1(x)))\n",
        "#         x = self.decoder_R2(self.dropout(self.decoder_L2(x)))\n",
        "#         x = self.decoder_R3(self.dropout(self.decoder_L3(x)))\n",
        "#         x = self.decoder_R4(self.dropout(self.decoder_L4(x)))\n",
        "#         x = self.decoder_R5(self.dropout(self.decoder_L5(x)))\n",
        "#         x = self.decoder_R6(self.dropout(self.decoder_L6(x)))\n",
        "#         x = self.decoder_R7(self.dropout(self.decoder_L7(x)))\n",
        "#         x = self.decoder_R8(self.dropout(self.decoder_L8(x)))\n",
        "#         x = self.decoder_R9(self.decoder_L9(x)) # don't apply dropout to the AE output\n",
        "\n",
        "#         return x\n",
        "\n",
        "# # # init training network classes / architectures\n",
        "# # decoder_train = decoder()\n",
        "\n",
        "# # # push to cuda if cudnn is available\n",
        "# # if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
        "# #     decoder_train = decoder().cuda()\n"
      ],
      "metadata": {
        "id": "6_IWZYjtZSU6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# implementation of the shallow decoder network\n",
        "# containing only a single layer\n",
        "class shallow_decoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(shallow_decoder, self).__init__()\n",
        "\n",
        "        # specify layer 1 - in 3, out 618\n",
        "        self.decoder_L1 = nn.Linear(in_features=3, out_features=ori_subset_transformed.shape[1], bias=True) # add linearity\n",
        "        nn.init.xavier_uniform_(self.decoder_L1.weight)  # init weights according to [9]\n",
        "        self.decoder_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True) # add non-linearity according to [10]\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # define forward pass through the network\n",
        "        x = self.decoder_R1(self.decoder_L1(x)) # don't apply dropout to the AE output\n",
        "\n",
        "        return x\n",
        "\n",
        "# init training network classes / architectures\n",
        "decoder_train = shallow_decoder()\n",
        "\n",
        "# push to cuda if cudnn is available\n",
        "if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
        "    decoder_train = shallow_decoder().cuda()\n"
      ],
      "metadata": {
        "id": "05hNI-EriAxI"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the optimization criterion / loss function\n",
        "loss_function = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "# define learning rate and optimization strategy\n",
        "learning_rate = 1e-3\n",
        "#learning_rate = 1e-2\n",
        "encoder_optimizer = torch.optim.Adam(encoder_train.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = torch.optim.Adam(decoder_train.parameters(), lr=learning_rate)\n",
        "\n",
        "# specify training parameters\n",
        "#changed the number of epochs to 30\n",
        "#num_epochs = 30\n",
        "num_epochs = 5\n",
        "mini_batch_size = 128\n",
        "\n",
        "# convert pre-processed data to pytorch tensor\n",
        "#torch_dataset = torch.from_numpy(ori_subset_transformed.values).float()\n",
        "torch_dataset = torch.from_numpy(ori_subset_transformed.astype(np.float32).values).float() # Convert all columns to float32\n",
        "\n",
        "# convert to pytorch tensor - none cuda enabled\n",
        "dataloader = DataLoader(torch_dataset, batch_size=mini_batch_size, shuffle=True, num_workers=0)\n",
        "# note: we set num_workers to zero to retrieve deterministic results\n",
        "\n",
        "# determine if CUDA is available at compute node\n",
        "if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
        "    dataloader = DataLoader(torch_dataset.cuda(), batch_size=mini_batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "l_EcNTrAZaua"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# init collection of mini-batch losses\n",
        "losses = []\n",
        "\n",
        "# convert encoded transactional data to torch Variable\n",
        "data = autograd.Variable(torch_dataset)\n",
        "\n",
        "# train autoencoder model\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # init mini batch counter\n",
        "    mini_batch_count = 0\n",
        "\n",
        "    # determine if CUDA is available at compute node\n",
        "    if(torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
        "\n",
        "        # set networks / models in GPU mode\n",
        "        encoder_train.cuda()\n",
        "        decoder_train.cuda()\n",
        "\n",
        "    # set networks in training mode (apply dropout when needed)\n",
        "    encoder_train.train()\n",
        "    decoder_train.train()\n",
        "\n",
        "    # start timer\n",
        "    start_time = datetime.now()\n",
        "\n",
        "    # iterate over all mini-batches\n",
        "    for mini_batch_data in dataloader:\n",
        "\n",
        "        # increase mini batch counter\n",
        "        mini_batch_count += 1\n",
        "\n",
        "        # convert mini batch to torch variable\n",
        "        mini_batch_torch = autograd.Variable(mini_batch_data)\n",
        "\n",
        "        # =================== (1) forward pass ===================================\n",
        "\n",
        "        # run forward pass\n",
        "        z_representation = encoder_train(mini_batch_torch) # encode mini-batch data\n",
        "        mini_batch_reconstruction = decoder_train(z_representation) # decode mini-batch data\n",
        "\n",
        "        # =================== (2) compute reconstruction loss ====================\n",
        "\n",
        "        # determine reconstruction loss\n",
        "        reconstruction_loss = loss_function(mini_batch_reconstruction, mini_batch_torch)\n",
        "\n",
        "        # =================== (3) backward pass ==================================\n",
        "\n",
        "        # reset graph gradients\n",
        "        decoder_optimizer.zero_grad()\n",
        "        encoder_optimizer.zero_grad()\n",
        "\n",
        "        # run backward pass\n",
        "        reconstruction_loss.backward()\n",
        "\n",
        "        # =================== (4) update model parameters ========================\n",
        "\n",
        "        # update network parameters\n",
        "        decoder_optimizer.step()\n",
        "        encoder_optimizer.step()\n",
        "\n",
        "        # =================== monitor training progress ==========================\n",
        "\n",
        "        # print training progress each 1'000 mini-batches\n",
        "        if mini_batch_count % 1000 == 0:\n",
        "\n",
        "            # print the training mode: either on GPU or CPU\n",
        "            mode = 'GPU' if (torch.backends.cudnn.version() != None) and (USE_CUDA == True) else 'CPU'\n",
        "\n",
        "            # print mini batch reconstuction results\n",
        "            now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
        "            end_time = datetime.now() - start_time\n",
        "            print('[LOG {}] training status, epoch: [{:04}/{:04}], batch: {:04}, loss: {}, mode: {}, time required: {}'.format(now, (epoch+1), num_epochs, mini_batch_count, np.round(reconstruction_loss.item(), 4), mode, end_time))\n",
        "\n",
        "            # reset timer\n",
        "            start_time = datetime.now()\n",
        "\n",
        "    # =================== evaluate model performance =============================\n",
        "\n",
        "    # set networks in evaluation mode (don't apply dropout)\n",
        "    encoder_train.cpu().eval()\n",
        "    decoder_train.cpu().eval()\n",
        "\n",
        "    # reconstruct encoded transactional data\n",
        "    reconstruction = decoder_train(encoder_train(data))\n",
        "\n",
        "    # determine reconstruction loss - all transactions\n",
        "    reconstruction_loss_all = loss_function(reconstruction, data)\n",
        "\n",
        "    # collect reconstruction loss\n",
        "    losses.extend([reconstruction_loss_all.item()])\n",
        "\n",
        "    # print reconstuction loss results\n",
        "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
        "    print('[LOG {}] training status, epoch: [{:04}/{:04}], loss: {:.10f}'.format(now, (epoch+1), num_epochs, reconstruction_loss_all.item()))\n",
        "\n",
        "    # =================== save model snapshot to disk ============================\n",
        "\n",
        "    # save trained encoder model file to disk\n",
        "    encoder_model_name = \"ep_{}_encoder_model.pth\".format((epoch+1))\n",
        "    torch.save(encoder_train.state_dict(), os.path.join(\"/content/models\", encoder_model_name))\n",
        "\n",
        "    # save trained decoder model file to disk\n",
        "    decoder_model_name = \"ep_{}_decoder_model.pth\".format((epoch+1))\n",
        "    torch.save(decoder_train.state_dict(), os.path.join(\"/content/models\", decoder_model_name))\n",
        "\n",
        "# plot the training progress\n",
        "plt.plot(range(0, len(losses)), losses)\n",
        "plt.xlabel('[training epoch]')\n",
        "plt.xlim([0, len(losses)])\n",
        "plt.ylabel('[reconstruction-error]')\n",
        "#plt.ylim([0.0, 1.0])\n",
        "plt.title('AENN training performance')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "jYi6EMM7ZgLq",
        "outputId": "cf8b46ee-b978-4126-d161-da5d54099aca"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOG 20250508-01:49:13] training status, epoch: [0001/0005], batch: 1000, loss: 0.0733, mode: GPU, time required: 0:00:02.054276\n",
            "[LOG 20250508-01:49:15] training status, epoch: [0001/0005], batch: 2000, loss: 0.0379, mode: GPU, time required: 0:00:01.989131\n",
            "[LOG 20250508-01:49:17] training status, epoch: [0001/0005], batch: 3000, loss: 0.0322, mode: GPU, time required: 0:00:02.031767\n",
            "[LOG 20250508-01:49:19] training status, epoch: [0001/0005], batch: 4000, loss: 0.0302, mode: GPU, time required: 0:00:02.015520\n",
            "[LOG 20250508-01:49:21] training status, epoch: [0001/0005], loss: 0.0297319070\n",
            "[LOG 20250508-01:49:23] training status, epoch: [0002/0005], batch: 1000, loss: 0.0273, mode: GPU, time required: 0:00:02.019331\n",
            "[LOG 20250508-01:49:25] training status, epoch: [0002/0005], batch: 2000, loss: 0.0252, mode: GPU, time required: 0:00:01.985991\n",
            "[LOG 20250508-01:49:27] training status, epoch: [0002/0005], batch: 3000, loss: 0.0215, mode: GPU, time required: 0:00:02.006413\n",
            "[LOG 20250508-01:49:29] training status, epoch: [0002/0005], batch: 4000, loss: 0.0199, mode: GPU, time required: 0:00:01.989715\n",
            "[LOG 20250508-01:49:31] training status, epoch: [0002/0005], loss: 0.0204292797\n",
            "[LOG 20250508-01:49:33] training status, epoch: [0003/0005], batch: 1000, loss: 0.0194, mode: GPU, time required: 0:00:02.042137\n",
            "[LOG 20250508-01:49:35] training status, epoch: [0003/0005], batch: 2000, loss: 0.0197, mode: GPU, time required: 0:00:01.981812\n",
            "[LOG 20250508-01:49:37] training status, epoch: [0003/0005], batch: 3000, loss: 0.0188, mode: GPU, time required: 0:00:01.979492\n",
            "[LOG 20250508-01:49:39] training status, epoch: [0003/0005], batch: 4000, loss: 0.0177, mode: GPU, time required: 0:00:02.003169\n",
            "[LOG 20250508-01:49:41] training status, epoch: [0003/0005], loss: 0.0179412626\n",
            "[LOG 20250508-01:49:43] training status, epoch: [0004/0005], batch: 1000, loss: 0.0174, mode: GPU, time required: 0:00:01.995343\n",
            "[LOG 20250508-01:49:44] training status, epoch: [0004/0005], batch: 2000, loss: 0.0176, mode: GPU, time required: 0:00:01.953928\n",
            "[LOG 20250508-01:49:46] training status, epoch: [0004/0005], batch: 3000, loss: 0.0164, mode: GPU, time required: 0:00:01.981790\n",
            "[LOG 20250508-01:49:48] training status, epoch: [0004/0005], batch: 4000, loss: 0.0164, mode: GPU, time required: 0:00:01.958847\n",
            "[LOG 20250508-01:49:51] training status, epoch: [0004/0005], loss: 0.0166904703\n",
            "[LOG 20250508-01:49:53] training status, epoch: [0005/0005], batch: 1000, loss: 0.0162, mode: GPU, time required: 0:00:02.032084\n",
            "[LOG 20250508-01:49:55] training status, epoch: [0005/0005], batch: 2000, loss: 0.0163, mode: GPU, time required: 0:00:01.995153\n",
            "[LOG 20250508-01:49:57] training status, epoch: [0005/0005], batch: 3000, loss: 0.017, mode: GPU, time required: 0:00:01.977711\n",
            "[LOG 20250508-01:49:59] training status, epoch: [0005/0005], batch: 4000, loss: 0.0157, mode: GPU, time required: 0:00:01.996858\n",
            "[LOG 20250508-01:50:01] training status, epoch: [0005/0005], loss: 0.0159964729\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'AENN training performance')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# restore pretrained model checkpoint\n",
        "# encoder_model_name = \"ep_10_encoder_model.pth\"\n",
        "# decoder_model_name = \"ep_10_decoder_model.pth\"\n",
        "encoder_model_name = \"ep_5_encoder_model.pth\"\n",
        "decoder_model_name = \"ep_5_decoder_model.pth\"\n",
        "\n",
        "# init training network classes / architectures\n",
        "encoder_eval = shallow_encoder()\n",
        "decoder_eval = shallow_decoder()\n",
        "# encoder_eval = encoder()\n",
        "# decoder_eval = decoder()\n",
        "\n",
        "# load trained models\n",
        "encoder_eval.load_state_dict(torch.load(os.path.join(\"/content/models\", encoder_model_name)))\n",
        "decoder_eval.load_state_dict(torch.load(os.path.join(\"/content/models\", decoder_model_name)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHME62IvZodU",
        "outputId": "c45b6275-83e2-436f-fa13-1259a41a7ab1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert encoded transactional data to torch Variable\n",
        "data = autograd.Variable(torch_dataset)\n",
        "\n",
        "# set networks in evaluation mode (don't apply dropout)\n",
        "encoder_eval.eval()\n",
        "decoder_eval.eval()\n",
        "\n",
        "# reconstruct encoded transactional data\n",
        "reconstruction = decoder_eval(encoder_eval(data))"
      ],
      "metadata": {
        "id": "24hd0nh2ZrWR"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# determine reconstruction loss - all transactions\n",
        "reconstruction_loss_all = loss_function(reconstruction, data)\n",
        "\n",
        "# print reconstruction loss - all transactions\n",
        "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
        "print('[LOG {}] collected reconstruction loss of: {:06}/{:06} transactions'.format(now, reconstruction.size()[0], reconstruction.size()[0]))\n",
        "print('[LOG {}] reconstruction loss: {:.10f}'.format(now, reconstruction_loss_all.item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24CIqfivZt0y",
        "outputId": "c97c7dce-d91e-49f8-8372-6fdd1cb68fdd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOG 20250508-01:50:03] collected reconstruction loss of: 533009/533009 transactions\n",
            "[LOG 20250508-01:50:03] reconstruction loss: 0.0159964729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# init binary cross entropy errors\n",
        "reconstruction_loss_transaction = np.zeros(reconstruction.size()[0])\n",
        "\n",
        "# iterate over all detailed reconstructions\n",
        "for i in range(0, reconstruction.size()[0]):\n",
        "\n",
        "    # determine reconstruction loss - individual transactions\n",
        "    reconstruction_loss_transaction[i] = loss_function(reconstruction[i], data[i]).item()\n",
        "\n",
        "    if(i % 100000 == 0):\n",
        "\n",
        "        ### print conversion summary\n",
        "        now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
        "        print('[LOG {}] collected individual reconstruction loss of: {:06}/{:06} transactions'.format(now, i, reconstruction.size()[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiOs7Rx8Zvog",
        "outputId": "4165a0cc-7fde-4a50-8337-9c801caff717"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOG 20250508-01:50:03] collected individual reconstruction loss of: 000000/533009 transactions\n",
            "[LOG 20250508-01:50:08] collected individual reconstruction loss of: 100000/533009 transactions\n",
            "[LOG 20250508-01:50:14] collected individual reconstruction loss of: 200000/533009 transactions\n",
            "[LOG 20250508-01:50:19] collected individual reconstruction loss of: 300000/533009 transactions\n",
            "[LOG 20250508-01:50:24] collected individual reconstruction loss of: 400000/533009 transactions\n",
            "[LOG 20250508-01:50:29] collected individual reconstruction loss of: 500000/533009 transactions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# init binary cross entropy errors\n",
        "reconstruction_loss_transaction = np.zeros(reconstruction.size()[0])\n",
        "\n",
        "# iterate over all detailed reconstructions\n",
        "for i in range(0, reconstruction.size()[0]):\n",
        "\n",
        "    # determine reconstruction loss - individual transactions\n",
        "    reconstruction_loss_transaction[i] = loss_function(reconstruction[i], data[i]).item()\n",
        "\n",
        "    if(i % 100000 == 0):\n",
        "\n",
        "        ### print conversion summary\n",
        "        now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
        "        print('[LOG {}] collected individual reconstruction loss of: {:06}/{:06} transactions'.format(now, i, reconstruction.size()[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h7SHdreZxZ0",
        "outputId": "eb02ef20-fd3d-4ed8-e319-8ddcf9754bc2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOG 20250508-01:50:31] collected individual reconstruction loss of: 000000/533009 transactions\n",
            "[LOG 20250508-01:50:36] collected individual reconstruction loss of: 100000/533009 transactions\n",
            "[LOG 20250508-01:50:42] collected individual reconstruction loss of: 200000/533009 transactions\n",
            "[LOG 20250508-01:50:47] collected individual reconstruction loss of: 300000/533009 transactions\n",
            "[LOG 20250508-01:50:52] collected individual reconstruction loss of: 400000/533009 transactions\n",
            "[LOG 20250508-01:50:57] collected individual reconstruction loss of: 500000/533009 transactions\n"
          ]
        }
      ]
    }
  ]
}